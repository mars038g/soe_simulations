---
title: "Simulation study for trend detection in IEA"
output:
  pdf_document: 
  word_document: default
  html_document:
    df_print: paged
indent: yes
geometry: margin=1in
bibliography: SOE simulations.bib
csl: ices-journal-of-marine-science.csl
documentclass: ouparticle
self_contained: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.path='figures/',
                      dev = c('png')) 

data.dir <- here::here("data.dir")
r.dir <- here::here("R")

# list of all packages required
packages <- c("stringi","boot","tinytex","Kendall","zoo","zyp",
              "trend","dplyr","AICcmodavg","nlme",
              "gtools","tidyr","stringr","ggplot2",
              "data.table","scales","RColorBrewer",
              "colorspace","mccr","cowplot","gridExtra","grid")

installLoadPackages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE,repos='http://cran.us.r-project.org')
    sapply(pkg, require, character.only = TRUE)
}

installLoadPackages(packages)

#GLS model selection function
source(file.path(r.dir,"fit_lm.R"))

#A funciton to run simulations
source(file.path(r.dir,"sim_function.R"))

#A function to create confusion matrices
source(file.path(r.dir,"conf_mat.R"))

#Simulation parameters
load(file.path(data.dir, "sim_param.Rdata"))

#2017 SOE report data
load(file.path(data.dir,'SOE_data_2017.RData'))

#List of fields from 2017 SOE report
load(file.path(data.dir,"SOE_fields.Rdata"))

#Label facets
label <- function(variable,value){
  return(facet_names[value])
}

#Color palette
pal <- colorRampPalette(c("white","darkred"))

#set seed
set.seed(123)

#Choose to run simulations
run <- F

#Choose to save new data 
save_clean <- F

#Numbers of simulations
nsims <- 100

# ARsd <- .54^.5 #standard deviation of time series
# ARsd_up95 <- 0.93^.5 #95% CI for variance
# 
# #AR strengths
# NOAR <- list()
# medAR <- 0.433
# strongAR <- 0.8

```



```{r preliminary analyses, echo = F, fig.align="center", fig.width = 8, fig.asp = 0.35, fig.cap="Frequency of estimated slopes (A), autocorrelation strengths (B), and time series variances (C) in data considered for inclusion in the 2017 State of the Ecosystem report. The solid red lines (A-C) represent distribution means, and dashed red lines (A, C) show the upper 95\\% confidence intervals for estimated trend slope and variance. \\label{Fig1}", warning=FALSE}

#A function to *approximate* starting simulation parameters with linear models------------------------
nlm <- function(field, lin = NULL, norm = NULL){
  time <- SOE.data[SOE.data$Var == field,]$Time
  end = max(time)
  time = time[1:which(time == end)]
  
  var <- SOE.data[SOE.data$Var == field,]$Value
  var <- var[1:length(time)]
  
  
  if(norm == TRUE){
    var = (var-mean(var))/sd(var)
  } else {
    var = var
  }
  
  if(lin == TRUE){
    time <- c(1:length(time))
    mod <- lm(var ~ time)
    int <- mod$coefficients[1]
    beta <- mod$coefficients[2]
  } else if (lin == FALSE){
    time <- c(1:length(time))
    time2 <- time^2
    mod <- lm(var ~ time + time2)
    int <- mod$coefficients[1]
    beta <- mod$coefficients[c(2,3)]
  }
  out <- c(int, beta)
  return(out)
}

#A function to estimate AR(p) parameters--------------------------------------------------------------
handle_arima <- function(field, a){
  tryCatch(
    {
      x.ts <- SOE.data %>% 
        filter(Var == field) %>% 
        mutate(Value = (Value-mean(.$Value))/sd(.$Value)) %>% #normalize
        arrange(Time) %>% #arrange
        dplyr::select(Time, Value) 
      
      res <- lm(Value ~ Time, data = x.ts)$residuals
      
      mod <- arima(x = res, order = c(a,0,0))
      
      if (a == 2){
        out <- data.frame(ar1 = mod$coef[1],
                          ar2 = mod$coef[2],
                          var = mod$sigma2,
                          field = field)
      } else {
        out <- data.frame(ar1 = mod$coef[1],
                          ar2 = NA,
                          var = mod$sigma2,
                          field = field)
       
      }
      
      return(out)
    },
    error=function(error_message) {
      message(error_message)
      return(data.frame(ar1 = NA,
                          ar2 = NA,
                          var = NA,
                          field = field))
    }
  )
}

#Estimate AR(1)
ar1.out <- NULL
for (i in fields){
  assign("ar1.out",rbind(handle_arima(i, a = 1), ar1.out))
}

#Estimate AR(2)
ar2.out <- NULL
for (i in fields){
  assign("ar2.out",rbind(handle_arima(i, a = 2), ar2.out))
}

#Estimate linear coefficients
beta_lin <- mapply(nlm, fields, lin = TRUE, norm = TRUE)
lin_coefficients <- data.frame("Fields"  = fields,
                               "Intercept" = beta_lin[1,],
                               "beta1" = beta_lin[2,])

#Data summaries---------------------------------------------------------------------------------------

#regression slopes
abs_beta <- abs(beta_lin[2,]) 
mean_beta1_linear <- mean(abs_beta)
upper_95_beta1 <- quantile(x = abs_beta, probs = 0.95)

#AR(1)
mean_ar1 <- mean(ar1.out$ar1, na.rm = T)
upper_95_ar1 <- quantile(x = ar1.out$ar1, probs = 0.95, na.rm = TRUE)

#Variance
iv_mean_ar1 <- mean(ar1.out$var, na.rm = T)
upper_95_iv_ar1 <- quantile(x = ar1.out$var, probs = 0.95, na.rm = TRUE)
upper_75_iv_ar1 <- quantile(x = ar1.out$var, probs = 0.75, na.rm = TRUE)
lower_25_iv_ar1 <- quantile(x = ar1.out$var, probs = 0.25, na.rm = TRUE)

#AR(2)
mean_ar2_coef1 <- mean(ar2.out$ar1, na.rm = T)
# mean_ar2_coef2 <- mean(ar2.out$ar2, na.rm = T)
mean_ar2_coef2 <- 0.2
iv_mean_ar2 <- mean(ar2.out$var, na.rm = T)

trend.df <- data.frame(Var = c("none","weak","med","strong"),
                       Value = c(0,0.026, 0.051, 0.147))

#Save clean data--------------------------------------------------------------------------------------

if (save_clean){
  
 save(mean_beta1_linear, upper_95_beta1,
     mean_ar1, upper_95_ar1,
     iv_mean_ar1, upper_75_iv_ar1,
     lower_25_iv_ar1,
     mean_ar2_coef1, mean_ar2_coef2,
     iv_mean_ar2, trend.df,
     file = file.path(data.dir,"sim_param.rdata"))

}

#Build plots------------------------------------------------------------------------------------------

beta <- ggplot(data = lin_coefficients, aes(x = abs(beta1))) +
    geom_histogram(bins = 40, 
                 fill = "lightblue", color = "deepskyblue4",
                 position = "dodge") +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,16.5)) +
  xlab(expression("|"~alpha[1]~"|")) +
  ylab("Frequency") +
  geom_vline(aes(xintercept = mean_beta1_linear), col = "indianred", size = 1) +
  geom_vline(aes(xintercept = upper_95_beta1), col = "indianred", size = 1, linetype = "dashed") +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10)) +
  labs(tag = "A")

 ar1 <- ggplot(data = ar1.out, aes(x = ar1)) +
  geom_histogram(bins = 124, binwidth = 0.05,
                 fill = "lightblue", color = "deepskyblue4",
                 position = "dodge") +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,13)) +
  xlab(expression(rho)) +
  ylab("") +
  geom_vline(aes(xintercept = mean_ar1), col = "indianred", size = 1) +
   geom_vline(aes(xintercept = upper_95_ar1), col = "indianred", size = 1, linetype = "dashed") +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10)) +
  labs(tag = "B")

iv <- ggplot(data = ar1.out, aes(x = var)) +
  geom_histogram(bins = 124, binwidth = 0.05,
                fill = "lightblue", color = "deepskyblue4",
                 position = "dodge") +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,16.5)) +
  xlab("Residual Variance") +
  ylab("") +
  geom_vline(aes(xintercept = iv_mean_ar1), col = "indianred", size = 1) +
  geom_vline(aes(xintercept = upper_75_iv_ar1), col = "indianred", size = 1, linetype = "dashed") +
  geom_vline(aes(xintercept = lower_25_iv_ar1), col = "indianred", size = 1, linetype = "dashed") +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10)) +
  labs(tag = "C")

param_plots <- cowplot::plot_grid(beta, ar1, iv, nrow = 1)

ggsave(param_plots,filename = "figures/fig1-parameters.tiff", device = "tiff", dpi = 300)
```


```{r assessing model power, echo = F}
if (run){
message("SIM 1 - ORIGINAL")
#AR1
out_ar1 <- NULL
noAR <- 0
for (r in c("noAR","mean_ar1","upper_95_ar1")){
  for (n in c(10,20,30)){
    for (t in c("none","weak","med","strong")){
      for (i in 1:nsims){      
        if (i %in% seq(1,nsims,nsims/20)){
          print(paste("sim =",i,"series length =",n,"trend =",t,"ar =",r))
        }
        
        assign("out_ar1",rbind(out_ar1, test.series(ar.order = 1,
                                                    rho = r,
                                                    series.length = n,
                                                    trend.strength = t,
                                                    var = iv_mean_ar1,
                                                    nsims = nsims))) 
      }
    }
  }
}

#AR1 with 0.95 quantile of variance sample distribution
#75 and 25; include that we repeated for different levels of variance and similar patterns existed etc.
message("SIM 2 - multiple var")
var2_ar1 <- NULL
noAR <- 0
for (r in c("noAR","mean_ar1","upper_95_ar1")){
  for (n in c(10,20,30)){
    for (t in c("none","weak","med","strong")){
      for (v in c("upper_75_iv_ar1","lower_25_iv_ar1")){
        for (i in 1:nsims){      
        if (i %in% seq(1,nsims,nsims/20)){
          print(paste("sim =",i,"series length =",n,"trend =",t,"ar =",r,"var = ",v))
        }
        
        assign("var2_ar1",rbind(var2_ar1, test.series(ar.order = 1,
                                                    rho = r,
                                                    series.length = n,
                                                    trend.strength = t,
                                                    var = get(v),
                                                    nsims = nsims))) 
        }
      }
    }
  }
}

message("SIM 3 - AR2")
#AR2
#Rewrite fit_lm to include AR1, AR2 and normally distributed
out_ar2 <- NULL
 for (n in c(10,20,30)){
   for (t in c("none","weak","med","strong")){
        for (i in 1:nsims){      
          if (i %in% seq(1,nsims,nsims/20)){
            print(paste("sim =",i,"series length =",n,"trend =",t))
          }
          
          out <- try(test.series(ar.order = 2,
                                series.length = n,
                                trend.strength = t,
                                rho = NA,
                                var = iv_mean_ar2,
                                nsims = nsims))
          if (class(out) == "try-error"){
            message("BROKEN")
            next
            
          } else {
            assign("out_ar2",rbind(out_ar2, out)) 
          }
          
      }
    }
  }

message("SIM 4 - NULL CASE")
#strong AR and no trend 
null_case <- NULL
for (r in c("upper_95_ar1")){
  for (n in seq(250,650,50)){
    for (t in c("none")){
      for (i in 1:nsims){      
        if (i %in% seq(1,nsims,nsims/20)){
          print(paste("sim =",i,"series length =",n,"trend =",t,"ar =",r))
        }
        
        assign("null_case",rbind(null_case, test.series(ar.order = 1,
                                                    rho = r,
                                                    series.length = n,
                                                    trend.strength = t,
                                                    var = iv_mean_ar1,
                                                    nsims = nsims))) 
        }
      }
    }
  }

  if (save_clean){
    save(null_case, out_ar1, out_ar2, var2_ar1, file = file.path(data.dir,"simulation_results.Rdata"))
  }

} else {
  load(file.path(data.dir, "simulation_results.Rdata"))
}


```

```{r simulation results processing, echo = F}


set_levels <- function(df){
  df$trend <- df %>%
                pull(trend) %>%
                plyr::mapvalues(.,from = c("none","weak","med","strong"),
                                to = c("No trend", "Weak trend","Med. trend", "Strong trend")) %>% 
                factor(., levels=c('Strong trend','Med. trend','Weak trend','No trend'))
  
  if (max(as.numeric(df$series.length))==30){
    df$series.length <- df %>% 
        pull(series.length) %>% 
        factor(.,levels = c(10,20,30))
  } else {
    df$series.length <- df %>% 
        pull(series.length) %>% 
        factor(.,levels = seq(50,650,50))
  }
  
  
  df$test <- df %>% 
    pull(test) %>% 
    plyr::mapvalues(., from = c("gls","mk","pw"), 
                    to = c("GLS","Mann-Kendall","MK-TFPW")) %>% 
    factor(.,levels = c("GLS","Mann-Kendall","MK-TFPW"))
  
  if (is.na(df$rho2[1])){
    df <- df %>%
      mutate(rho1 = round(rho1, 3)) %>% 
      mutate(rho1 = plyr::mapvalues(rho1,from = c(0,0.455,0.9),
                                 to = c("No AR","Med. AR","Strong AR")),
                           rho1)
    if (length(unique(df$rho1)) == 3){
      df$rho1 <- df %>% 
        pull(rho1) %>% 
        factor(., levels = c("No AR","Med. AR", "Strong AR"))
    }
    
  } else {
      df$trend <- df %>% 
        pull(trend) %>% 
        factor(., levels = c("No trend","Weak trend", "Med. trend","Strong trend"))
  }
  
  df <- df %>% dplyr::rename(Method = test)
  
  return(df)

}

out_ar1_int <- set_levels(out_ar1)
var2_ar1_int <- set_levels(var2_ar1)
out_ar2_int <- set_levels(out_ar2)
null_case_int <- set_levels(null_case)


#Aggregate p values
p_agg <- function(df){
  df %>% 
    group_by(var, Method, series.length, rho1, trend) %>% 
    dplyr::summarise(prop = length(p[p < 0.05])/n())
}

agg_out_ar1 <- p_agg(out_ar1_int)
agg_var2_ar1 <- p_agg(var2_ar1_int)
agg_out_ar2 <- p_agg(out_ar2_int) #Only one level of rho in AR(2); extra grouping doesn't matter
agg_null_case <- p_agg(null_case_int)


#some values for text
gls <- agg_out_ar1 %>% dplyr::filter(rho1 == "No AR", Method == "GLS")
pw <- agg_out_ar1 %>% filter(rho1 == "No AR", Method == "MK-TFPW")

perc_change1 <- abs(mean(pw$prop) - mean(gls$prop))/mean(gls$prop) * 100
nom_p <- agg_out_ar1 %>% filter(trend == "No trend", rho1 == "No AR", series.length == 10)
strAR_noTR <- agg_out_ar1 %>% filter(trend  == "No trend", rho1 == "Strong AR", series.length == 30)

perc_change_mk <- round(abs(strAR_noTR[strAR_noTR$Method == "Mann-Kendall",]$prop - strAR_noTR[strAR_noTR$Method == "GLS",]$prop)/
                        (strAR_noTR[strAR_noTR$Method == "Mann-Kendall",]$prop) * 100,0)

perc_change_pw <- round(abs(strAR_noTR[strAR_noTR$Method == "MK-TFPW",]$prop - strAR_noTR[strAR_noTR$Method == "GLS",]$prop)/
                        (strAR_noTR[strAR_noTR$Method == "MK-TFPW",]$prop) * 100,0)

#sample size effect
ss1 <- agg_out_ar1 %>% filter(trend  == "No trend", rho1 == "Strong AR", series.length == 10)
ss2 <- agg_out_ar1 %>% filter(trend  == "No trend", rho1 == "Strong AR",  series.length == 30)

pw1 <- ss1[ss1$Method == "MK-TFPW",]$prop
pw2 <- ss2[ss2$Method == "MK-TFPW",]$prop

pw_ss <- round((pw1 - pw2)/pw1, 2)*100

gls1 <- ss1[ss1$Method == "GLS",]$prop
gls2 <- ss2[ss2$Method == "GLS",]$prop

gls_ss <- round((gls1 - gls2)/gls1, 2)*100

```
  
```{r power analysis figure, echo = F, fig.align='center',fig.cap="Barplots showing the propotion of significant trends (\\textit{P}<0.05) to number of total simulations. Subplots are representative of different autocorrelation ($\\rho = 0, .43, .8$) and trend scenarios ($\\alpha_{1} = 0.026, .051$), with time series length increasing along the x axis. Colored bars show results from different tests for trend. \\label{Fig2}"}

agg_ar1_plt <- ggplot(agg_out_ar1,aes(color = Method, y = prop, 
                  x = series.length)) +
  geom_bar(aes(fill = Method), stat = "identity",  position="dodge",
            size = 0.5, color = "black") +
  facet_grid(trend ~ rho1, labeller = labeller(tbl)) +
  ylab("Proportion significant") +
  xlab("Series length") +
  scale_fill_brewer(palette = "PuBu", direction = -1) +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10))
ggsave(agg_ar1_plt,filename = "figures/fig2-ar1.tiff", device = "tiff", dpi = 300)
```

```{r power analysis var, echo = F, fig.align='center',fig.cap="Barplots showing the propotion of significant trends (\\textit{P}<0.05) to number of total simulations. Subplots are representative of different autocorrelation ($\\rho = 0, .43, .8$) and trend scenarios ($\\alpha_{1} = 0.026, .051$), with time series length increasing along the x axis. Colored bars show results from different tests for trend. \\label{Fig2}"}

var_df <- agg_var2_ar1 %>% 
  ungroup() %>% 
  mutate(var = round(var,1)) %>% 
  mutate(var = plyr::mapvalues(var, from = c(0.3,0.8),
                               to = c("Low",
                                      "High"))) 
var_df$var <- factor(var_df$var,
                           levels = c("Low",
                                      "High"))


iq_variance_sim <- var_df %>% 
    mutate(abbr_var = if_else(stringr::str_detect(var, "Low"),
                              "low","high")) %>% 
    mutate(var2 = paste(abbr_var, series.length, Method),
           var3 = paste(series.length, Method),
           var4 = paste(abbr_var, var),
           var5 = paste(rho1, series.length)) 

iq_variance_sim$var3 <- factor(iq_variance_sim$var3,
                    levels = c("10 GLS",
                               "10 Mann-Kendall",
                               "10 MK-TFPW",
                               "20 GLS",
                               "20 Mann-Kendall",
                               "20 MK-TFPW",
                               "30 GLS",
                               "30 Mann-Kendall",
                               "30 MK-TFPW"))


iq_variance_plt <- iq_variance_sim %>% 
  filter(trend == "Weak trend",
         series.length == 30) %>%
  ggplot() +
  geom_point(aes(x = var3,
                  y = prop,
                  color = series.length,
                 group = var3,
                  shape = var),size = 2.5, color = "black") +
  # geom_line(aes(x = var3,
  #                 y = prop,
  #                 color = series.length,
  #                group = var3),size = 1) +
  guides(color = F,
         shape = guide_legend(title = "Sim. variance"))+
  facet_grid(trend ~ rho1) +
  ylab("Proportion significant") +
  xlab("Test") +
  scale_x_discrete(labels = rep(c("GLS","MK","MK-TFPW"),3))+
  scale_color_manual( values = c("#3690C0", "#A6BDDB", "black")) +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10),
        axis.text.x = element_text(angle = 45, vjust = 0.6))


ggsave(iq_variance_plt,filename = "figures/fig5-iq-variance-sims.tiff", device = "tiff", dpi = 300)
```



```{r power subset figure, fig.align="center", fig.asp=0.45, eval = T, echo = F, fig.show = "h", fig.cap= "Barplot showing the ratio of number of rejections (\\textit{P}<0.05) to number of total simulations, when simulations were created under the parameters of no trend $(\\alpha_{1} = 0)$, strong autocorrelation $(\\rho = 0.8)$, and series lengths between \\textit{N} = 50 to $N = 500$. The dashed red line shows the nominal rejection rate of 0.05.\\label{Fig3}"}


ar1_extended <- agg_null_case %>% 
  filter(trend == "No trend") %>% 
ggplot(aes(x = series.length,
           y = prop,
           group = Method,
           fill = Method)) +
  geom_bar(stat = "identity",position="dodge", color = "black") +
  geom_hline(yintercept=0.05, linetype="dashed", 
             color = "red", size=1) +
  ylab("Proportion significant") +
  xlab("Series length") +
  scale_fill_brewer(palette = "PuBu", direction = -1) +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10))
ggsave(ar1_extended,filename = "figures/fig3-ar1-extended.tiff", device = "tiff", dpi = 300)
```



```{r ar2 figure, fig.align="center", fig.asp=0.45, eval = T, echo = F, fig.show = "h", fig.cap= ""}


ar2_plt <- ggplot(agg_out_ar2,aes(color = Method, y = prop, 
                  x = series.length)) +
  geom_bar(aes(fill = Method), stat = "identity",  position="dodge",
            size = 0.5, color = "black") +
  facet_grid(. ~ trend, labeller = labeller(tbl)) +
  ylab("Proportion significant") +
  xlab("Series length") +
  scale_fill_brewer(palette = "PuBu", direction = -1) +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10))

ggsave(ar2_plt,filename = "figures/fig6-ar2-sims.tiff", device = "tiff", dpi = 300)
```

```{r confusion matrices, echo = F, fig.align='center', out.extra='trim={0cm 5cm 0cm 0cm},clip', fig.cap= 'Confusion matrices showing aggregate results from testing for trend across all combinations autocorrelation and trend strength when N=30. Colors represent the performance of individual cells across tests, where cells shaded in red indicate a poorer outcome. For example, when N=30, the GLS procedure falsely predicted a trend when there was none in 11.1\\% of cases (white), whereas this was true in 22.1\\% of Mann-Kendall simulations (red).\\label{Fig4}' }

create_conf <- function(N){
  mk <- cbind(conf_mat(out_ar1_int,test = "Mann-Kendall", N = N), test = rep('mk',4))
  pw <- cbind(conf_mat(out_ar1_int, test = "MK-TFPW", N = N), test = rep('pw',4))
  gls <- cbind(conf_mat(out_ar1_int, test = "GLS", N = N), test = rep('gls',4))
  fin <- rbind(mk, pw, gls)
  fin$group <- factor(paste(fin$x,fin$y))
  
  
  #Make matrices for white = good and orange = bad
  fin_dif <- fin %>% group_by(group) %>%
    mutate(val, best_dif = ifelse(group == "actual no predicted no"|
                                    group == "actual yes predicted yes",
                                  (abs(max(val) - val)), #best_dif is for assigning colors
                                  (abs(min(val) - val)))) %>% 
    mutate(test = plyr::mapvalues(test, from = c("mk","pw","gls"),
                                  to = c("Mann-Kendall","MK-TFPW","GLS")))
  
  #plot
  plt <- ggplot(data = fin_dif, aes(x,y, fill = best_dif)) +
    facet_grid(. ~ test)+
    geom_tile(aes(size = 1),color = "grey", size = 1)  +
    scale_fill_gradientn(colors = pal(10))+
    geom_text(aes(x = x, y = y, label = round(val,3)),size = 6) +
    theme(legend.position = "none",
          axis.line = element_blank(),
          axis.title=element_blank(),
          axis.text.y = element_text(margin = margin(t = 0, r = -6,
                                                     b = 0, l = 0),
                                     size = 10),
          axis.text.x = element_text(margin = margin(t = -3, r = 0,
                                                     b = 15, l = 0),
                                     size = 10),
          axis.ticks.y=element_blank(),
          axis.ticks.x=element_blank(),
          plot.title = element_text(hjust = -0.1),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank())
  return(plt)
}


conf_mat <- create_conf(N = 30)

ggsave(conf_mat,filename = "figures/fig4-conf-mat.tiff", device = "tiff", dpi = 300)
```

```{r trend slope, fig.align="center", echo = F, fig.cap="Violin plots showing probability densities of estimated trends from GLS and Sen's slope procedures under varying autocorrelation scenarios $(\\rho = 0, 0.43, 0.8)$ and simulation lengths (N = 10, 20, 30). Black lines represent the median slope estimate, and red lines the true slope. For this exercise, the GLS model selection procedure was constrained to fit only linear models of trend.\\label{Fig5}"}

df <- out_ar1_int %>% filter(!is.na(slope_pred), p < 0.05) 

levels(df$Method) <- c("GLS","Mann-Kendall","Sen's slope")

trend_magnitude <- ggplot(df, aes(factor(series.length), slope_pred)) + 
  geom_hline(aes(yintercept = slope_true,linetype = "True trend"), color = "red", size = 0.5) +
  geom_violin(aes(fill = Method), adjust = 0.5, scale = "width",
              draw_quantiles = 0.5, size = 0.3) +
  scale_linetype_manual(name = "", values = 1,
                      guide = guide_legend(override.aes = list(color = "red"))) +
  facet_grid(trend ~ rho1) +
  ylab("Predicted slope") +
  xlab("Series length") +
  scale_fill_brewer(palette = "PuBu") +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10))
ggsave(trend_magnitude,filename = "figures/fig7-trend-magnitude.tiff", device = "tiff", dpi = 300)
```


```{r sd of trend estimates, fig.align = "center", echo = F, fig.cap = "Sample standard deviations of trend estimates derived from Sen's slope and GLS methods across autocorrelation strengths ($\\rho = 0, 0.433, 0.8$), trend strengths ($\\alpha_{1} = 0, 0.026, 0.052, 0.147$), and trend detection methods. \\label{Fig6}"}
stdev <- NULL

for (t in c("GLS","Sen's slope")){
  for (k in c(10,20,30)){
    for (j in c('No trend','Weak trend','Med. trend','Strong trend')){
      for (i in c("No AR","Med. AR","Strong AR")){
        out <- sd(df[df$Method == t &df$series.length == k &
                       df$trend == j & df$rho1 == i, ]$slope_pred)
        
        out <- data.frame(stdev = out,
                          Autocorrelation = i,
                          `Trend strength` = j,
                          `Series length` = k,
                          `Method` = t)
        assign('stdev',rbind(stdev,out))
      }
      
    }
    
  }
  
}
names(stdev)[c(3,4)] <- c("Trend strength","Series length")

stdev <- stdev %>% mutate(Autocorrelation, Autocorrelation = plyr::mapvalues(Autocorrelation,
                                                                    from = c("no AR",
                                                                             "medium AR",
                                                                             "strong AR"),
                                                                    to = c(0, 0.433, 0.8))) %>%
  mutate(`Trend strength`, `Trend strength` = plyr::mapvalues(`Trend strength`,
                                                                    from = c("no trend",
                                                                             "weak trend",
                                                                             "medium trend",
                                                                             "strong trend"),
                                                                    to = c("No trend",
                                                                             "Weak trend",
                                                                             "Medium trend",
                                                                             "Strong trend")))



ggplot(data = stdev) + geom_line(aes(x = Autocorrelation, y = stdev,
                                     group = `Trend strength`, color = `Trend strength`),
                                 size = 1) +
  # geom_point(aes(x = Autocorrelation, y = stdev,
  #                                    group = `Trend strength`),
  #            color = "black",
  #                                size = 1)+
  facet_grid(`Method` ~ `Series length`)+
  ylab("Standard deviation of trend estimates") +
  xlab(expression(paste("Autocorrelation (",rho,")"))) +
  scale_color_brewer(palette = "Spectral", direction = -1) +
  theme_bw() +
  theme(plot.title = element_blank(),
        strip.background = element_blank(),
        axis.text = element_text(size = 9),
        axis.title = element_text(size = 10),
        strip.text = element_text(size = 10))

```

